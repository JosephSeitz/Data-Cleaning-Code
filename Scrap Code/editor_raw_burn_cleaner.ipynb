{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tools used for clean up\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What Burn would you like to clean? (1-6):7\n",
      "Would you like to change the NaN's to a different value? (y/n):n\n"
     ]
    }
   ],
   "source": [
    "### Global\n",
    "Burn = int(input(\"What Burn would you like to clean? (1-6):\"))\n",
    "fill_nan = np.nan\n",
    "\n",
    "change_nan = input(\"Would you like to change the NaN's to a different value? (y/n):\")\n",
    "if change_nan == \"y\":\n",
    "    fill_nan = input(\"What to replace NaN's with? ex: 9999:\")\n",
    "\n",
    "if Burn == 1: \n",
    "    path = \"http://35.12.130.8/study/2018-SERDP/02-raw-data/ALL-RAW/SERDP_SLEF_Burn_data/SERDP_SLEF_Sonic/SLEF_first_set_truss_burns/SERDP%20burn%20one/\"\n",
    "if Burn == 2:\n",
    "    path =\"http://35.12.130.8/study/2018-SERDP/02-raw-data/ALL-RAW/SERDP_SLEF_Burn_data/SERDP_SLEF_Sonic/SLEF_first_set_truss_burns/SERDP%20burn%20two/\"\n",
    "if Burn == 3:\n",
    "    path = \"http://35.12.130.8/study/2018-SERDP/02-raw-data/ALL-RAW/SERDP_SLEF_Burn_data/SERDP_SLEF_Sonic/SLEF_first_set_truss_burns/SERDP%20burn%20three/\"\n",
    "if Burn == 4:\n",
    "    path = \"http://35.12.130.8/study/2018-SERDP/02-raw-data/ALL-RAW/SERDP_SLEF_Burn_data/SERDP_SLEF_Sonic/SLEF_second_set_truss_burns/SLEF%20second%20set%20truss%20burns/SERDP%20burn%20four/\"\n",
    "if Burn == 5:\n",
    "    path = \"http://35.12.130.8/study/2018-SERDP/02-raw-data/ALL-RAW/SERDP_SLEF_Burn_data/SERDP_SLEF_Sonic/SLEF_second_set_truss_burns/SLEF%20second%20set%20truss%20burns/SERDP%20burn%20five/\"\n",
    "if Burn  == 6:\n",
    "    path = \"http://35.12.130.8/study/2018-SERDP/02-raw-data/ALL-RAW/SERDP_SLEF_Burn_data/SERDP_SLEF_Sonic/SLEF_second_set_truss_burns/SLEF%20second%20set%20truss%20burns/SERDP%20burn%20six/\"\n",
    "if Burn ==7:\n",
    "    path = 'http://35.12.130.8/study/2018-SERDP/02-raw-data/ALL-RAW/SERDP_SLEF_Burn_data/SERDP_SLEF_Sonic/SLEF_third_set_truss_burns/SERDP_Burn_Seven/'\n",
    "if Burn ==8:\n",
    "    path = \"http://35.12.130.8/study/2018-SERDP/02-raw-data/ALL-RAW/SERDP_SLEF_Burn_data/SERDP_SLEF_Sonic/SLEF_third_set_truss_burns/SERDP_Burn_Eight/\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_df(path, file, Burn):\n",
    "   \n",
    "        \n",
    "    df = pd.read_csv(path+file, skiprows=4, na_values='NAN')\n",
    "    headers_df = pd.read_csv(path+file,skiprows=1,nrows = 0)\n",
    "    \n",
    "    df.columns=list(headers_df) \n",
    "    df.fillna(value=fill_nan, inplace=True)\n",
    "    df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finding where to cut the data, needs all df, gives time_start and time_end \n",
    "### needed for truncater()\n",
    "\n",
    "def timestamp_matcher(df_names, file_num):\n",
    "    \n",
    "    \n",
    "    min_lst, max_lst =[],[]\n",
    "\n",
    "    for i in df_names:\n",
    "        min_lst.append(i[\"TIMESTAMP\"].min())\n",
    "        max_lst.append(i[\"TIMESTAMP\"].max())\n",
    "\n",
    "        fmt = \"File: {} | Start: {} | End: {}\" \n",
    "    for i in range(len(min_lst)):\n",
    "        print(fmt.format(file_num[i], min_lst[i],max_lst[i] ))\n",
    "\n",
    "    time_start, time_end = max(min_lst), min(max_lst)    \n",
    "    print()\n",
    "    print(\"Start timestamp Pulled:\",time_start, \"| End Timestamp Pulled:\",time_end)\n",
    "\n",
    "    finder = ['5T', '30S','S','.1S']\n",
    "    for n in range(len(finder)):\n",
    "        test_start=list(pd.date_range(start=time_start, end=time_end,freq = finder[n]))\n",
    "        test_end = test_start[::-1]\n",
    "        time=[]\n",
    "        for t in range(len(test_start)): \n",
    "            for df in range(len(df_names)):\n",
    "                if test_start[t] not in list(df_names[df][\"TIMESTAMP\"]):\n",
    "                    break\n",
    "                else:\n",
    "                    time.append(test_start[t])\n",
    "                    break\n",
    "            if len(time)==1:\n",
    "                if t ==0 or n == len(finder)-1:\n",
    "                    time_start = test_start[t]\n",
    "                else:\n",
    "                    time_start = test_start[t-1]\n",
    "                break\n",
    "\n",
    "\n",
    "        time=[]\n",
    "        for t in range(len(test_end)):\n",
    "            for df in range(len(df_names)):\n",
    "                if test_end[t] not in list(df_names[df][\"TIMESTAMP\"]):\n",
    "                    break\n",
    "                else:\n",
    "                    time.append(test_end[t])\n",
    "                    break\n",
    "            if len(time)==1:\n",
    "                if t ==0 or n == len(finder)-1:\n",
    "                    time_end = test_end[t]\n",
    "                else:\n",
    "                    time_end = test_end[t-1]\n",
    "                break\n",
    "    print()\n",
    "    print(\"Timestamp that can actually be used to trim due to gaps:\")\n",
    "    print(\"Start Time:\", str(time_start), \"| End Time:\", str(time_end))\n",
    "    \n",
    "    return time_start, time_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutter(df, time_start, time_end):\n",
    "\n",
    "    s_index = df.index[df[\"TIMESTAMP\"]==time_start].tolist()[-1]\n",
    "    e_index = df.index[df[\"TIMESTAMP\"]==time_end].tolist()[0]\n",
    "    df = df.truncate(before=s_index, after= e_index)\n",
    "    df=df.reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat(df):\n",
    "    #### Check for repeated times\n",
    "\n",
    "    lst=list(df[\"TIMESTAMP\"])\n",
    "    u = list(np.unique(lst)) \n",
    "    if len(u) != len(df):\n",
    "        repeat_1, repeat_2, repeat_index = [],[],[]\n",
    "        for i in u:\n",
    "            x = lst.count(i)\n",
    "            if x>1:\n",
    "                y=[j for j,val in enumerate(lst) if val==i]\n",
    "                repeat_index.append(y)\n",
    "                repeat_1.append(list(df.loc[y[0],:]))\n",
    "                repeat_2.append(list(df.loc[y[1],:]))\n",
    "        if len(repeat_index)>0:\n",
    "            print(\"Yikes! Number of repeated times: \",len(repeat_index),)\n",
    "            print(\"Start:\", repeat_index[0],\"End:\",repeat_index[-1])\n",
    "            print(\"Time stamp repeats:\",repeat_1[0][0],\"-\", repeat_1[-1][0], \"Length\", len(repeat_1))\n",
    "            return repeat_2[-1][0]\n",
    "    else:\n",
    "        print(\"Hurray! No time Repeats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_columns(df):\n",
    "    year_lst  = list(np.full(len(df),fill_nan))\n",
    "    month_lst = list(np.full(len(df),fill_nan))\n",
    "    day_lst   = list(np.full(len(df),fill_nan))\n",
    "    hour_lst  = list(np.full(len(df),fill_nan))\n",
    "    min_lst   = list(np.full(len(df),fill_nan))\n",
    "    second_lst= list(np.full(len(df),fill_nan))\n",
    "\n",
    "    ### Parcing the timestamps and seperating them \n",
    "    time_stmp_lst = list(df[\"TIMESTAMP\"].astype(str))\n",
    "    for i in range(len(df)):\n",
    "        time_step    = time_stmp_lst[i].replace(\"-\", \",\").replace(\":\",\",\").replace(\" \",\",\").replace(\"/\",',').split(\",\")\n",
    "        year_lst[i]  = \"{:.0f}\".format(float(time_step[0])).zfill(4)\n",
    "        month_lst[i] = \"{:.0f}\".format(float(time_step[1])).zfill(2)\n",
    "        day_lst[i]   = \"{:.0f}\".format(float(time_step[2])).zfill(2)\n",
    "        hour_lst[i]  = \"{:.0f}\".format(float(time_step[3])).zfill(2)\n",
    "        min_lst[i]   = \"{:.0f}\".format(float(time_step[4])).zfill(2)\n",
    "        second_lst[i]= \"{:.1f}\".format(float(time_step[5])).zfill(4)\n",
    "    \n",
    "    df_time = pd.DataFrame()\n",
    "    df_time[\"YYYY\"] = year_lst\n",
    "    df_time[\"MM\"]   = month_lst\n",
    "    df_time[\"DD\"]   = day_lst\n",
    "    df_time[\"Hour\"] = hour_lst\n",
    "    df_time[\"Min\"]  = min_lst\n",
    "    df_time[\"Sec\"]  = second_lst\n",
    "    \n",
    "    return df_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Global variables \n",
    "files = [\"TOA5_2878.WGNover10Hz.dat\",\"TOA5_2879.ts_data.dat\", \"TOA5_4390.ts_data.dat\",\\\n",
    "         \"TOA5_4975.ts_data.dat\",\"TOA5_4976.ts_data.dat\",\"TOA5_10442.ts_data.dat\",\"TOA5_11585.ts_data.dat\"]\n",
    "files =[\"TOA5_2878.WGNover10Hz.dat\",\"TOA5_2879.ts_data.dat\",\\\n",
    "             \"TOA5_3884.ts_data.dat\", \"TOA5_4390.ts_data.dat\",\\\n",
    "             \"TOA5_4975.ts_data.dat\",\"TOA5_4976.ts_data.dat\",\n",
    "             \"TOA5_10442.ts_data.dat\", \"TOA5_11584.ts_data.dat\",\\\n",
    "             \"TOA5_11585.ts_data.dat\"]\n",
    "files = [\"TOA5_2879.ts_data.dat\",\\\n",
    "             \"TOA5_3884.ts_data.dat\", \"TOA5_4390.ts_data.dat\",\\\n",
    "             \"TOA5_4975.ts_data.dat\",\"TOA5_4976.ts_data.dat\",\n",
    "             \"TOA5_10442.ts_data.dat\", \"TOA5_11584.ts_data.dat\",\\\n",
    "             \"TOA5_11585.ts_data.dat\"]\n",
    "\n",
    "#df_2878 = file_to_df(path, files[0], Burn)### Don't use on burns 1 and 2, tower_data\n",
    "df_2879 = file_to_df(path, files[0], Burn)\n",
    "df_3884 = file_to_df(path, files[1], Burn)\n",
    "df_4390 = file_to_df(path, files[2], Burn)\n",
    "df_4975 = file_to_df(path, files[3], Burn)\n",
    "\n",
    "df_4976 = file_to_df(path, files[4], Burn)\n",
    "df_10442 = file_to_df(path, files[5], Burn)\n",
    "\n",
    "df_11584 = file_to_df(path, files[6], Burn)\n",
    "df_11585 = file_to_df(path, files[7], Burn)\n",
    "\n",
    "#d= file_to_df(path,files[7],Burn)\n",
    "#r= file_to_df(path,files[8], Burn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 2879 | Start: 2018-05-09 10:12:04.200000 | End: 2018-05-09 11:06:56.100000\n",
      "File: 3884 | Start: 2018-05-09 10:12:04.200000 | End: 2018-05-09 11:06:56.100000\n",
      "File: 4390 | Start: 2018-05-09 10:12:04.200000 | End: 2018-05-09 11:06:56.100000\n",
      "File: 4975 | Start: 2018-05-09 10:12:04.200000 | End: 2018-05-09 11:06:56.100000\n",
      "File: 4976 | Start: 2018-03-17 15:15:24.800000 | End: 2018-05-09 11:11:44.200000\n",
      "File: 10442 | Start: 2018-03-17 14:40:50.900000 | End: 2018-05-09 11:14:15.200000\n",
      "File: 11584 | Start: 2018-03-04 10:24:28 | End: 2018-05-09 11:11:52.200000\n",
      "File: 11585 | Start: 2018-03-17 14:42:01.800000 | End: 2018-05-09 11:12:42.800000\n",
      "\n",
      "Start timestamp Pulled: 2018-05-09 10:12:04.200000 | End Timestamp Pulled: 2018-05-09 11:06:56.100000\n",
      "\n",
      "Timestamp that can actually be used to trim due to gaps:\n",
      "Start Time: 2018-05-09 10:12:04.200000 | End Time: 2018-05-09 11:02:04.200000\n",
      "Would you like to trim the data to these timestamps? (y/n):y\n"
     ]
    }
   ],
   "source": [
    "df_names= [df_2879, df_3884, df_4390, df_4975, df_4976, df_10442,\\\n",
    "               df_11584, df_11585]\n",
    "file_num = [\"2879\",\"3884\",\"4390\",\"4975\",\"4976\",\\\n",
    "                \"10442\",'11584',\"11585\"]\n",
    "t_s,t_e = timestamp_matcher(df_names,file_num)\n",
    "t_s='2018-05-09 10:15:38.4'\n",
    "trim_df = input(\"Would you like to trim the data to these timestamps? (y/n):\")\n",
    "if trim_df.lower() == \"y\":\n",
    "        df_2879 = cutter(df_2879, t_s, t_e)\n",
    "        df_3884 = cutter(df_3884, t_s, t_e)\n",
    "        df_4390 = cutter(df_4390, t_s, t_e)\n",
    "        df_4975 = cutter(df_4975, t_s, t_e)\n",
    "        df_4976 = cutter(df_4976, t_s, t_e)\n",
    "        df_10442 = cutter(df_10442, t_s, t_e)\n",
    "        df_11584 = cutter(df_11584, t_s, t_e)\n",
    "        df_11585 = cutter(df_11585, t_s, t_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 2879 | Start: 2018-03-17 14:36:23.900000 | End: 2018-05-09 11:14:01.300000\n",
      "File: 4390 | Start: 2018-03-17 14:45:46.600000 | End: 2018-05-09 11:12:56.700000\n",
      "File: 4975 | Start: 2018-03-17 15:08:08.400000 | End: 2018-05-09 11:14:53.900000\n",
      "File: 4390 | Start: 2018-03-17 15:15:24.800000 | End: 2018-05-09 11:11:44.200000\n",
      "File: 4975 | Start: 2018-03-17 14:40:50.900000 | End: 2018-05-09 11:14:15.200000\n",
      "File: 4976 | Start: 2018-03-17 14:42:01.800000 | End: 2018-05-09 11:12:42.800000\n",
      "\n",
      "Start timestamp Pulled: 2018-03-17 15:15:24.800000 | End Timestamp Pulled: 2018-05-09 11:11:44.200000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-65ba4ef9bdb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_names\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf_2879\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_4390\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_4975\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_4976\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_10442\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_11585\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfile_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"2879\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"4390\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"4975\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"4390\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"4975\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"4976\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"10442\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"11585\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mt_s\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimestamp_matcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mt_s\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"2018-05-09 08:26:56.1\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrim_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Would you like to trim the data to these timestamps? (y/n):\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-7d4f1990a46c>\u001b[0m in \u001b[0;36mtimestamp_matcher\u001b[1;34m(df_names, file_num)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mtest_start\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TIMESTAMP\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mmaybe_box_datetimelike\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mmaybe_box_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;31m# turn a datetime like into a Timestamp/timedelta as needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_names= [df_2879,df_4390,df_4975,df_4976,df_10442,df_11585]\n",
    "file_num = [\"2879\",\"4390\",\"4975\",\"4390\",\"4975\",\"4976\",\"10442\",\"11585\"]\n",
    "t_s,t_e = timestamp_matcher(df_names,file_num)\n",
    "t_s=\"2018-05-09 08:26:56.1\"\n",
    "trim_df = input(\"Would you like to trim the data to these timestamps? (y/n):\")\n",
    "if trim_df.lower() == \"y\":\n",
    "    #df_2878 = cutter(df_2878, t_s, t_e)\n",
    "    df_2879 = cutter(df_2879, t_s, t_e)\n",
    "    df_4390 = cutter(df_4390, t_s, t_e)\n",
    "    df_4975 = cutter(df_4975, t_s, t_e)\n",
    "    df_4976 = cutter(df_4976, t_s, t_e)\n",
    "    df_10442 = cutter(df_10442, t_s, t_e)\n",
    "    df_11585 = cutter(df_11585, t_s, t_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_names= [df_2878,df_2879,df_4390,df_4975,df_4976,df_10442,df_11585]\n",
    "file_num = [\"2878\",\"2879\",\"4390\",\"4975\",\"4390\",\"4975\",\"4976\",\"10442\",\"11585\"]\n",
    "#### use the t_s and t_e from above\n",
    "#t_s,t_e = timestamp_matcher(df_names)\n",
    "\n",
    "check = input(\"Would you like to check for repeated timestamps? Note: if there are repeats, it takes at least 10 mins if there are repeats (y/n):\")\n",
    "\n",
    "if check == \"y\":\n",
    "    end_repeat_times = []\n",
    "    for i in range(len(df_names)):\n",
    "        print(file_num[i]+':')\n",
    "        end_repeat_times.append(repeat(df_names[i])) \n",
    "cut_out_repeat = \"n\"\n",
    "for i in end_repeat_times:\n",
    "    if str(i) != \"None\":\n",
    "        cut_out_repeat = input(\"Would you like to cut all data at the end of the repeated times? (y/n):\")\n",
    "        t_s = i\n",
    "if cut_out_repeat == \"y\":     \n",
    "    #df_2878 = cutter(df_2878, t_s, t_e)\n",
    "    df_2879 = cutter(df_2879, t_s, t_e)\n",
    "    df_4390 = cutter(df_4390, t_s, t_e)\n",
    "    df_4975 = cutter(df_4975, t_s, t_e)\n",
    "    df_4976 = cutter(df_4976, t_s, t_e)\n",
    "    df_10442 = cutter(df_10442, t_s, t_e)\n",
    "    df_11585 = cutter(df_11585, t_s, t_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grabbing Sonic data from specific files\n",
    "sonic_columns=[\"Ux_\",\"Uy_\",\"Uz_\",\"Ts_\"]\n",
    "time_columns_lst=[\"YYYY\",\"MM\",\"DD\",\"Hour\",\"Min\",\"Sec\"]\n",
    "\n",
    "df_A1, df_A2, df_A3, df_A4 = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "df_B1, df_B2, df_B3, df_B4 = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "df_C1, df_C2, df_C3, df_C4 = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "df_D1, df_D2, df_D3, df_D4 = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "\n",
    "a_row_lst = [df_A1, df_A2, df_A3, df_A4]\n",
    "b_row_lst = [df_B1, df_B2, df_B3, df_B4]\n",
    "c_row_lst = [df_C1, df_C2, df_C3, df_C4]\n",
    "d_row_lst = [df_D1, df_D2, df_D3, df_D4 ]\n",
    "\n",
    "all_sonics = a_row_lst+ b_row_lst + c_row_lst +d_row_lst\n",
    "\n",
    "###  Burns 1-6 truss:\n",
    "df_4975_time, df_2879_time = time_columns(df_4975), time_columns(df_2879)\n",
    "df_11585_time, df_4976_time = time_columns(df_11585), time_columns(df_4976)\n",
    "### WG Nover 10hz\n",
    "df_2878_time = time_columns(df_2878)\n",
    "df_WGNover = pd.DataFrame()\n",
    "\n",
    "for col in sonic_columns:\n",
    "    df_WGNover[col+\"1\"] = df_2878[col+\"1\"]\n",
    "for t in time_columns_lst:\n",
    "    df_WGNover[t] = df_2878_time[t]\n",
    "\n",
    "    \n",
    "for n in range(len(a_row_lst)):\n",
    "    \n",
    "    for i in range(len(sonic_columns)):\n",
    "        a_row_lst[n][sonic_columns[i]+str(n+1)] = df_4975[sonic_columns[i]+str(n+1)]\n",
    "        b_row_lst[n][sonic_columns[i]+str(n+1)] = df_2879[sonic_columns[i]+str(n+1)]\n",
    "        c_row_lst[n][sonic_columns[i]+str(n+1)] = df_11585[sonic_columns[i]+str(n+1)]\n",
    "        d_row_lst[n][sonic_columns[i]+str(n+1)] = df_4976[sonic_columns[i]+str(n+1)]\n",
    "    \n",
    "    for i in range(len(time_columns_lst)):\n",
    "        a_row_lst[n][time_columns_lst[i]]=df_4975_time[time_columns_lst[i]]\n",
    "        b_row_lst[n][time_columns_lst[i]]=df_2879_time[time_columns_lst[i]]\n",
    "        c_row_lst[n][time_columns_lst[i]]=df_11585_time[time_columns_lst[i]]\n",
    "        d_row_lst[n][time_columns_lst[i]]=df_4976_time[time_columns_lst[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Thermal Couple data\n",
    "time_columns_lst=[\"YYYY\",\"MM\",\"DD\",\"Hour\",\"Min\",\"Sec\"]\n",
    "\n",
    "df_B1_tc, df_B2_tc, df_B3_tc, df_B4_tc = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "df_C1_tc, df_C2_tc, df_C3_tc, df_C4_tc = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "\n",
    "first_tc_group = [ df_B1_tc, df_B3_tc, df_C1_tc, df_C3_tc]\n",
    "secnd_tc_group = [ df_B2_tc, df_B4_tc, df_C2_tc, df_C4_tc]\n",
    "\n",
    "df_10442_time, df_2879_time = time_columns(df_10442), time_columns(df_2879)\n",
    "df_4390_time, df_11585_time = time_columns(df_4390), time_columns(df_11585)\n",
    "\n",
    "t_c_lst_1 = [\"Temp_C(1)\",\"Temp_C(2)\",\"Temp_C(3)\",\"Temp_C(4)\",\"Temp_C(5)\",\"Temp_C(6)\",\"Temp_C(7)\"]\n",
    "t_c_lst_2 = [\"Temp_C(8)\",\"Temp_C(9)\",\"Temp_C(10)\",\"Temp_C(11)\",\"Temp_C(12)\",\"Temp_C(13)\",\"Temp_C(14)\"]\n",
    "\n",
    "df_tc_lst= [df_10442, df_2879, df_4390, df_11585]\n",
    "df_time_lst = [df_10442_time, df_2879_time, df_4390_time, df_11585_time] \n",
    "\n",
    "for j in range(len(first_tc_group)):\n",
    "    for i in range(len(t_c_lst_1)):\n",
    "        first_tc_group[j][t_c_lst_1[i]]= df_tc_lst[j][t_c_lst_1[i]]\n",
    "        secnd_tc_group[j][t_c_lst_2[i]]= df_tc_lst[j][t_c_lst_2[i]]\n",
    "    \n",
    "    for t in range(len(time_columns_lst)):\n",
    "        first_tc_group[j][time_columns_lst[t]]= df_time_lst[j][time_columns_lst[t]]\n",
    "        secnd_tc_group[j][time_columns_lst[t]]= df_time_lst[j][time_columns_lst[t]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating the directories to save the data\n",
    "cwd = os.getcwd()\n",
    "save_dir = \"Burn-\"+str(Burn)\n",
    "os.mkdir(cwd+\"/\" + save_dir)\n",
    "\n",
    "tc_dir =cwd+\"/\" + save_dir + \"/thermal_couples\"\n",
    "sonic_dir =cwd+\"/\" + save_dir + \"/sonics\"\n",
    "\n",
    "os.mkdir(tc_dir)\n",
    "os.mkdir(sonic_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the Sonic data\n",
    "save_as_lst = [\"A1\", \"A2\", \"A3\", \"A4\", \"B1\", \"B2\", \"B3\", \"B4\", \"C1\",\"C2\",\"C3\",\"C4\",\"D1\",\"D2\",\"D3\",\"D4\"]\n",
    "for i in range(len(all_sonics)):\n",
    "    all_sonics[i].to_csv(sonic_dir+'/'+save_as_lst[i]+\"_UVWT_Burn-\"+str(Burn)+\".txt\", sep='\\t',index=False)\n",
    "df_WGNover.to_csv(sonic_dir+'/WGNover_UVWT_Burn-'+str(Burn)+\".txt\",sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving Thermal Couple dataframes\n",
    "all_tc_group = first_tc_group + secnd_tc_group\n",
    "save_as_lst = [\"B1\", \"B2\", \"B3\", \"B4\", \"C1\",\"C2\",\"C3\",\"C4\"]\n",
    "for i in range(len(all_tc_group)):\n",
    "    all_tc_group[i] = all_tc_group[i].round(3)\n",
    "    all_tc_group[i].to_csv(tc_dir+'/'+save_as_lst[i]+\"_thermal_couple_Burn-\"+str(Burn)+\".txt\", sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### BURN 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 2879 | Start: 2018-03-17 14:36:23.900000 | End: 2018-05-09 11:14:01.300000\n",
      "File: 3884 | Start: 2018-05-08 17:57:11.400000 | End: 2018-05-09 11:15:12.100000\n",
      "File: 4390 | Start: 2018-03-17 14:45:46.600000 | End: 2018-05-09 11:12:56.700000\n",
      "File: 4975 | Start: 2018-03-17 15:08:08.400000 | End: 2018-05-09 11:14:53.900000\n",
      "File: 4976 | Start: 2018-03-17 15:15:24.800000 | End: 2018-05-09 11:11:44.200000\n",
      "File: 10442 | Start: 2018-03-17 14:40:50.900000 | End: 2018-05-09 11:14:15.200000\n",
      "File: 11584 | Start: 2018-03-04 10:24:28 | End: 2018-05-09 11:11:52.200000\n",
      "File: 11585 | Start: 2018-03-17 14:42:01.800000 | End: 2018-05-09 11:12:42.800000\n",
      "\n",
      "Start timestamp Pulled: 2018-05-08 17:57:11.400000 | End Timestamp Pulled: 2018-05-09 11:11:44.200000\n",
      "\n",
      "Timestamp that can actually be used to trim due to gaps:\n",
      "Start Time: 2018-05-09 08:23:09.900000 | End Time: 2018-05-09 11:07:11.400000\n",
      "Would you like to trim the data to these timestamps? (y/n):y\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-17badc328534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m \u001b[0msaver_b7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-17badc328534>\u001b[0m in \u001b[0;36msaver_b7\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msaver_b7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mall_sonics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_tc_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler_b7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m### Creating the directories to save the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-17badc328534>\u001b[0m in \u001b[0;36mcompiler_b7\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mdf_4975\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcutter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_4975\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m        \u001b[0;31m# df_4976 = cutter(df_4976, t_s, t_e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mdf_10442\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcutter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_10442\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mdf_11584\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcutter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_11584\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mdf_11585\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcutter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_11585\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-fcfd06be7616>\u001b[0m in \u001b[0;36mcutter\u001b[0;34m(df, time_start, time_end)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcutter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ms_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TIMESTAMP\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0me_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TIMESTAMP\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtime_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafter\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0me_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jul  2 18:18:26 2019\n",
    "\n",
    "@author: joey\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jul  1 14:33:38 2019\n",
    "\n",
    "@author: joey\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "### Global\n",
    "#Burn = int(input(\"What Burn would you like to clean? (7 or 8):\"))\n",
    "\n",
    "path = 'http://35.12.130.8/study/2018-SERDP/02-raw-data/ALL-RAW/SERDP_SLEF_Burn_data/SERDP_SLEF_Sonic/SLEF_third_set_truss_burns/SERDP_Burn_Seven/'\n",
    "\n",
    "Burn = 7\n",
    "def compiler_b7():\n",
    "    files = [\"TOA5_2879.ts_data.dat\",\\\n",
    "             \"TOA5_3884.ts_data.dat\", \"TOA5_4390.ts_data.dat\",\\\n",
    "             \"TOA5_4975.ts_data.dat\",\"TOA5_4976.ts_data.dat\",\n",
    "             \"TOA5_10442.ts_data.dat\", \"TOA5_11584.ts_data.dat\",\\\n",
    "             \"TOA5_11585.ts_data.dat\"]\n",
    "\n",
    "    file_num = [\"2879\",\"3884\",\"4390\",\"4975\",\"4976\",\\\n",
    "                \"10442\",'11584',\"11585\"]\n",
    "    ### First Loading the files into the script\n",
    "    #df_2878 = file_to_df(path, files[0])\n",
    "    \n",
    "    df_2879 = file_to_df(path, files[0],Burn)\n",
    "    df_3884 = file_to_df(path, files[1],Burn)\n",
    "    df_4390 = file_to_df(path, files[2], Burn)\n",
    "    df_4975 = file_to_df(path, files[3], Burn)\n",
    "    \n",
    "    df_4976 = file_to_df(path, files[4],Burn)\n",
    "    df_10442 = file_to_df(path, files[5], Burn)\n",
    "    \n",
    "    df_11584 = file_to_df(path, files[6],Burn)\n",
    "    df_11585 = file_to_df(path, files[7],Burn)\n",
    "    ### List of dataframes that is needed\n",
    "    df_names= [df_2879, df_3884, df_4390, df_4975, df_4976, df_10442,\\\n",
    "               df_11584, df_11585]\n",
    "\n",
    "    t_s,t_e = timestamp_matcher(df_names,file_num)\n",
    "    trim_df = input(\"Would you like to trim the data to these timestamps? (y/n):\")\n",
    "    if trim_df.lower() == \"y\":\n",
    "        df_2879 = cutter(df_2879, t_s, t_e)\n",
    "        df_3884 = cutter(df_3884, t_s, t_e)\n",
    "        df_4390 = cutter(df_4390, t_s, t_e)\n",
    "        df_4975 = cutter(df_4975, t_s, t_e)\n",
    "       # df_4976 = cutter(df_4976, t_s, t_e)\n",
    "        df_10442 = cutter(df_10442, t_s, t_e)\n",
    "        df_11584 = cutter(df_11584, t_s, t_e)\n",
    "        df_11585 = cutter(df_11585, t_s, t_e)\n",
    "\n",
    "    df_names= [ df_2879, df_3884, df_4390, df_4975, df_4976, df_10442,\\\n",
    "               df_11584, df_11585]\n",
    "    check = input(\"Would you like to check for repeated timestamps? Note: if there are repeats, it takes at least 10 mins if there are repeats (y/n):\")\n",
    "\n",
    "    if check == \"y\":\n",
    "        end_repeat_times = []\n",
    "        for i in range(len(df_names)):\n",
    "            print(file_num[i]+':')\n",
    "            end_repeat_times.append(repeat(df_names[i])) \n",
    "    cut_out_repeat = \"n\"\n",
    "    for i in end_repeat_times:\n",
    "        if str(i) != \"None\":\n",
    "            cut_out_repeat = input(\"Would you like to cut all data at the end of the repeated times? (y/n):\")\n",
    "            t_s = i\n",
    "    if cut_out_repeat == \"y\":     \n",
    "        df_2879 = cutter(df_2879, t_s, t_e)\n",
    "        df_3884 = cutter(df_3884, t_s, t_e)\n",
    "        df_4390 = cutter(df_4390, t_s, t_e)\n",
    "        df_4975 = cutter(df_4975, t_s, t_e)\n",
    "        df_4976 = cutter(df_4976, t_s, t_e)\n",
    "        df_10442 = cutter(df_10442, t_s, t_e)\n",
    "        df_11584 = cutter(df_11584, t_s, t_e)\n",
    "        df_11585 = cutter(df_11585, t_s, t_e)\n",
    "\n",
    "    ### Grabbing Sonic data from specific files\n",
    "    sonic_columns=[\"Ux_\",\"Uy_\",\"Uz_\",\"Ts_\"]\n",
    "    time_columns_lst=[\"YYYY\",\"MM\",\"DD\",\"Hour\",\"Min\",\"Sec\"]\n",
    "    \n",
    "    df_A1, df_A2, df_A3, df_A4 = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "    df_B1, df_B2, df_B3, df_B4 = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "    df_C1, df_C2, df_C3, df_C4 = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "    df_D1, df_D2, df_D3, df_D4 = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "    \n",
    "    a_row_lst = [df_A1, df_A2, df_A3, df_A4]\n",
    "    b_row_lst = [df_B1, df_B2, df_B3, df_B4]\n",
    "    c_row_lst = [df_C1, df_C2, df_C3, df_C4]\n",
    "    d_row_lst = [df_D1, df_D2, df_D3, df_D4 ]\n",
    "    \n",
    "    all_sonics = a_row_lst+ b_row_lst + c_row_lst +d_row_lst\n",
    "    \n",
    "    ###  Burns 7/8 truss:\n",
    "    df_4975_time, df_2879_time = time_columns(df_4975), time_columns(df_2879)\n",
    "    df_11585_time, df_4976_time = time_columns(df_11585), time_columns(df_4976)\n",
    "    df_3884_time, df_11584_time = time_columns(df_3884), time_columns(df_11584)\n",
    "    \n",
    "    df_10442_time = time_columns(df_10442)\n",
    "    df_4390_time = time_columns(df_4390)\n",
    "    \n",
    "    ### WG Nover 10hz\n",
    "    #df_2878_time = time_columns(df_2878)\n",
    "    #df_WGNover = pd.DataFrame()\n",
    "    \n",
    "    #for col in sonic_columns:\n",
    "     #   df_WGNover[col+\"1\"] = df_2878[col+\"1\"]\n",
    "    #for t in time_columns_lst:\n",
    "    #    df_WGNover[t] = df_2878_time[t]\n",
    "    \n",
    "        \n",
    "    for n in range(len(a_row_lst)):\n",
    "        \n",
    "        for i in range(len(sonic_columns)):\n",
    "            a_row_lst[n][sonic_columns[i]+str(n+1)] = df_4975[sonic_columns[i]+str(n+1)]\n",
    "            b_row_lst[n][sonic_columns[i]+str(n+1)] = df_10442[sonic_columns[i]+str(n+1)]\n",
    "            c_row_lst[n][sonic_columns[i]+str(n+1)] = df_11584[sonic_columns[i]+str(n+1)]\n",
    "            d_row_lst[n][sonic_columns[i]+str(n+1)] = df_4390[sonic_columns[i]+str(n+1)]\n",
    "        \n",
    "        for i in range(len(time_columns_lst)):\n",
    "            a_row_lst[n][time_columns_lst[i]]=df_4975_time[time_columns_lst[i]]\n",
    "            b_row_lst[n][time_columns_lst[i]]=df_10442_time[time_columns_lst[i]]\n",
    "            c_row_lst[n][time_columns_lst[i]]=df_11584_time[time_columns_lst[i]]\n",
    "            d_row_lst[n][time_columns_lst[i]]=df_4390_time[time_columns_lst[i]]\n",
    "\n",
    "    #### Thermal Couple data\n",
    "    time_columns_lst=[\"YYYY\",\"MM\",\"DD\",\"Hour\",\"Min\",\"Sec\"]\n",
    "    \n",
    "    df_B1_tc, df_B2_tc, df_B3_tc, df_B4_tc = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "    df_C1_tc, df_C2_tc, df_C3_tc, df_C4_tc = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "    \n",
    "    df_B5_tc, df_B6_tc, df_B7_tc = pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "    df_C5_tc, df_C6_tc, df_C7_tc = pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "    \n",
    "    t_c_lst_1 = [\"Temp_C(1)\",\"Temp_C(2)\",\"Temp_C(3)\",\"Temp_C(4)\",\"Temp_C(5)\",\"Temp_C(6)\",\"Temp_C(7)\"]\n",
    "    t_c_lst_2 = [\"Temp_C(8)\",\"Temp_C(9)\",\"Temp_C(10)\",\"Temp_C(11)\",\"Temp_C(12)\",\"Temp_C(13)\",\"Temp_C(14)\"]\n",
    "    \n",
    "    first_tc_group = [ df_B2_tc, df_B3_tc, df_B6_tc, df_B7_tc,\\\n",
    "                       df_C2_tc, df_C3_tc, df_C6_tc, df_C7_tc]\n",
    "    \n",
    "    secnd_tc_group = [ df_B1_tc, df_B4_tc, df_B5_tc,\\\n",
    "                      df_C1_tc, df_C4_tc, df_C5_tc]\n",
    "\n",
    "    df_tc_lst_1 = [df_4975, df_2879, df_3884, df_10442, df_11585, df_4976,\\\n",
    "                df_4390, df_11584]\n",
    "    \n",
    "    df_time_lst_1 =[df_4975_time, df_2879_time, df_3884_time, df_10442_time,\\\n",
    "                    df_11585_time, df_4976_time, df_4390_time, df_11584_time]\n",
    "    for j in range(len(first_tc_group)):\n",
    "        for i in range(len(t_c_lst_1)):\n",
    "            first_tc_group[j][t_c_lst_1[i]]= df_tc_lst_1[j][t_c_lst_1[i]]\n",
    "           \n",
    "        for t in range(len(time_columns_lst)):\n",
    "            first_tc_group[j][time_columns_lst[t]]= df_time_lst_1[j][time_columns_lst[t]]\n",
    "    \n",
    "    df_tc_lst_2 = [df_2879, df_4975, df_10442, df_4976, df_11585, df_11584]\n",
    "    \n",
    "    df_time_lst_2 = [df_2879_time, df_4975_time, df_10442_time, df_4976_time,\\\n",
    "                   df_11585_time, df_11584_time]\n",
    "    \n",
    "    for j in range(len(secnd_tc_group)):\n",
    "        for i in range(len(t_c_lst_2)):\n",
    "            secnd_tc_group[j][t_c_lst_2[i]]= df_tc_lst_2[j][t_c_lst_2[i]]\n",
    "           \n",
    "        for t in range(len(time_columns_lst)):\n",
    "            secnd_tc_group[j][time_columns_lst[t]]= df_time_lst_2[j][time_columns_lst[t]]\n",
    "   \n",
    "    all_tc_group = [df_B1_tc, df_B2_tc, df_B3_tc, df_B4_tc, df_B5_tc,\\\n",
    "                    df_B6_tc, df_B7_tc,df_C1_tc, df_C2_tc, df_C3_tc, df_C4_tc,\\\n",
    "                    df_C5_tc, df_C6_tc, df_C7_tc]\n",
    "    \n",
    "    return all_sonics, all_tc_group #, df_WGNover\n",
    "\n",
    "def saver_b7():\n",
    "    \n",
    "    all_sonics, all_tc_group = compiler_b7()\n",
    "    \n",
    "    ### Creating the directories to save the data\n",
    "    save_me = input(\"Would you like to save the data into the working directory? (y/n):\")\n",
    "    if save_me == \"y\":\n",
    "        cwd = os.getcwd()\n",
    "    else:\n",
    "        cwd = input(\"Full path of save directory:\")\n",
    "        \n",
    "    save_dir = \"Burn-\"+str(Burn)\n",
    "    os.mkdir(cwd+\"/\" + save_dir)\n",
    "    \n",
    "    tc_dir =cwd+\"/\" + save_dir + \"/thermal_couples\"\n",
    "    sonic_dir =cwd+\"/\" + save_dir + \"/sonics\"\n",
    "    \n",
    "    os.mkdir(tc_dir)\n",
    "    os.mkdir(sonic_dir)\n",
    "\n",
    "    ### Save the Sonic data\n",
    "    save_as_lst = [\"A1\", \"A2\", \"A3\", \"A4\", \"B1\", \"B2\", \"B3\", \"B4\", \"C1\",\"C2\",\\\n",
    "                   \"C3\",\"C4\",\"D1\",\"D2\",\"D3\",\"D4\"]\n",
    "    for i in range(len(all_sonics)):\n",
    "        sv_file = sonic_dir+'/'+save_as_lst[i]+\"_UVWT_Burn-\"+str(Burn)+\".txt\"\n",
    "        all_sonics[i].to_csv(sv_file, sep='\\t',index=False)\n",
    "    #df_WGNover.to_csv(sonic_dir+'/WGNover_UVWT_Burn-'+str(Burn)+\".txt\",sep='\\t',index=False)\n",
    "\n",
    "    ### Saving Thermal Couple dataframes\n",
    "    \n",
    "    save_as_lst = [\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\", \"C1\",\"C2\",\"C3\",\\\n",
    "                   \"C4\", \"C5\", \"C6\", \"C7\"]\n",
    "    \n",
    "    for i in range(len(all_tc_group)):\n",
    "        all_tc_group[i] = all_tc_group[i].round(3)\n",
    "        sv_file=tc_dir+'/'+save_as_lst[i]+\"_thermal_couple_Burn-\"+str(Burn)+\".txt\"\n",
    "        all_tc_group[i].to_csv(sv_file, sep='\\t',index=False)\n",
    "    print(\"You now have the Burn sonics and thermocouple saved\")\n",
    "\n",
    "\n",
    "\n",
    "saver_b7()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
