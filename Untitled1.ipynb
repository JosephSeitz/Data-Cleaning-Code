{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from Raw_Cleaner import timestamp_matcher, time_columns, file_to_df, cutter, \\\n",
    "    repeat, continuous_df, timestamp_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_columns(df):\n",
    "    \"\"\"\n",
    "    This function takes a df with a \"TIMESTAMP\" index/column and separates \n",
    "    the date and time atributes into different columns and creates a new df \n",
    "    with just the time columns separated\n",
    "    \n",
    "    input:\n",
    "        df - pandas dataframe with \"TIMESTAMP\" index\n",
    "        \n",
    "    output:\n",
    "        df_time - pandas dataframe with just the timestamp columns\n",
    "    \"\"\"\n",
    "    #Created nan lists to append to quickly \n",
    "    fill_nan = np.nan\n",
    "    year_lst  = list(np.full(len(df),fill_nan))\n",
    "    month_lst = list(np.full(len(df),fill_nan))\n",
    "    day_lst   = list(np.full(len(df),fill_nan))\n",
    "    hour_lst  = list(np.full(len(df),fill_nan))\n",
    "    min_lst   = list(np.full(len(df),fill_nan))\n",
    "    second_lst= list(np.full(len(df),fill_nan))\n",
    "\n",
    "    ### Parcing the timestamps and seperating them \n",
    "    time_stmp_lst = list(df[\"TIMESTAMP\"].astype(str))\n",
    "    for i in range(len(df)):\n",
    "        time_step    = time_stmp_lst[i].replace(\"-\", \",\").replace(\":\",\",\").replace(\" \",\",\").replace(\"/\",',').split(\",\")\n",
    "        year_lst[i]  = \"{:.0f}\".format(float(time_step[0])).zfill(4)\n",
    "        month_lst[i] = \"{:.0f}\".format(float(time_step[1])).zfill(2)\n",
    "        day_lst[i]   = \"{:.0f}\".format(float(time_step[2])).zfill(2)\n",
    "        hour_lst[i]  = \"{:.0f}\".format(float(time_step[3])).zfill(2)\n",
    "        min_lst[i]   = \"{:.0f}\".format(float(time_step[4])).zfill(2)\n",
    "        second_lst[i]= \"{:.1f}\".format(float(time_step[5])).zfill(4)\n",
    "    \n",
    "    title_list = [\"Sec\", \"Min\", \"Hr\", \"DD\", \"MM\", \"YYYY\"]\n",
    "    time_cols = [second_lst, min_lst, hour_lst, day_lst, month_lst, year_lst]\n",
    "    for i in range(len(title_list)):\n",
    "        \n",
    "        df.insert(0, column= title_list[i], value = time_cols[i])\n",
    "    df = df.drop(\"TIMESTAMP\", axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compiler():\n",
    "    path = \"/Users/joeyp/Desktop/Data-Cleaning-Code/\"\n",
    "    file = \"groundprofile_Wtower_LS2019_TC.csv\"\n",
    "\n",
    "    df = file_to_df(path,file,3,1,False)\n",
    "    df = df.drop(\"TIMESTAMP\", axis=1)\n",
    "    df.insert(0, column= \"TIMESTAMP\", value = list(df[\"TIMESTAMP (corrected)\"]))\n",
    "    df = df.drop(\"TIMESTAMP (corrected)\", axis=1)\n",
    "    df = timestamp_correction(df)\n",
    "    df = continuous_df(df, df[\"TIMESTAMP\"][0], df[\"TIMESTAMP\"][len(df)-1])\n",
    "\n",
    "    raw_col_A = [\"TIMESTAMP\", 'sctA_Ux_3m', 'sctA_Uy_3m', 'sctA_Uz_3m',\n",
    "           'sctA_Ts_3m', 'sctA_diag_rmy_3m', \"sctA_HBP_Mbar_3m\" ]\n",
    "    raw_col_B = [\"TIMESTAMP\", 'sctB_Ux_3m', 'sctB_Uy_3m', 'sctB_Uz_3m',\n",
    "           'sctB_Ts_3m', 'sctB_diag_rmy_3m', \"sctB_HBP_Mbar_3m\" ]\n",
    "    raw_col_C = [\"TIMESTAMP\", 'sctC_Ux_3m', 'sctC_Uy_3m', 'sctC_Uz_3m',\n",
    "           'sctC_Ts_3m', 'sctC_diag_rmy_3m', \"sctC_HBP_Mbar_3m\" ]\n",
    "    raw_col_D = [\"TIMESTAMP\", 'sctD_Ux_3m', 'sctD_Uy_3m', 'sctD_Uz_3m',\n",
    "           'sctD_Ts_3m', 'sctD_diag_rmy_3m', \"sctD_HBP_Mbar_3m\" ]\n",
    "    raw_cols_all = [raw_col_A, raw_col_B, raw_col_C, raw_col_D]\n",
    "\n",
    "    sonics = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    out_cols = [\"TIMESTAMP\", \"U(3m)\", \"V(3m)\", \"W(3m)\", \"T(3m)\",\"DIAG\", \"P(3m)\"]\n",
    "\n",
    "    df_A, df_B = pd.DataFrame(), pd.DataFrame()\n",
    "    df_C, df_D = pd.DataFrame(), pd.DataFrame()\n",
    "    df_list = [df_A, df_B, df_C, df_D]\n",
    "\n",
    "    for i in range(4):\n",
    "        df_list[i][out_cols] = df[raw_cols_all[i]]\n",
    "    \n",
    "    return df_list \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction():\n",
    "    df_list = compiler()\n",
    "    \n",
    "    #wind speed correction\n",
    "    m_speed,min_T = 40, float(-10)\n",
    "    u_fctr, v_fctr = -1, -1\n",
    "    \n",
    "    fmt = \"Default Corrections: {}*U, {}*V, Max Wind Speed=|{}| m/s, Min Temperature = {} C  \" \n",
    "    print(fmt.format(u_fctr,v_fctr,m_speed,min_T))\n",
    "    \n",
    "    nw_corct = input(\"Would you like to change these corrections? (y/n): \")\n",
    "    if nw_corct.lower() == \"y\":\n",
    "        u_fctr = float(input(\"What to multiply the U values by?:\"))\n",
    "        v_fctr = float(input(\"What to multiply the V values by?:\"))\n",
    "        m_speed = float(input(\"What bounds do you want for the wind speed? (m/s):\"))\n",
    "        min_T = float(input(\"What is the minimum temperatue? (C):\"))\n",
    "    \n",
    "    fill_nan = np.nan\n",
    "    change_nan = input(\"Would you like to change the NaN's to a different value? (y/n):\")\n",
    "    if change_nan == \"y\":\n",
    "        fill_nan = input(\"What to replace NaN's with? ex: 9999:\")\n",
    "    \n",
    "    for i in range(len(df_list)):\n",
    "        df_list[i] = apply_correction(df_list[i], u_fctr, v_fctr, m_speed, min_T, fill_nan)\n",
    "    \n",
    "    split_timestamp = input(\"Would like the TIMESTAMP column broken up? (y/n):\")\n",
    "    if split_timestamp.lower() == \"y\":\n",
    "        for i in range(len(df_list)):\n",
    "            df_list[i] = time_columns(df_list[i])\n",
    "    return df_list\n",
    "\n",
    "def apply_correction(df,u_fctr,v_fctr,m_speed,min_T,fill_nan):\n",
    "\n",
    "    ##For loop for all the sonics\n",
    "    df[\"U(3m)\"] *= u_fctr\n",
    "    df[\"V(3m)\"] *= v_fctr\n",
    "    \n",
    "    indx = []\n",
    "    for i in range(len(df)):\n",
    "        if df[\"DIAG\"][i] != 0.0:\n",
    "            df.at[i,[\"U(3m)\",\"V(3m)\",\"W(3m)\",\"T(3m)\"]] = fill_nan\n",
    "            indx.append(i)\n",
    "            indx.append(i)\n",
    "            indx.append(i)\n",
    "            indx.append(i)\n",
    "            continue\n",
    "        \n",
    "        if np.abs(df[\"U(3m)\"][i]) > m_speed:\n",
    "            df.at[i, \"U(3m)\"] = fill_nan\n",
    "            #df[\"U\"][i] =fill_nan\n",
    "            indx.append(i)\n",
    "            \n",
    "        if  np.abs(df[\"V(3m)\"][i])> m_speed:\n",
    "            df.at[i, \"V(3m)\"] = fill_nan\n",
    "            #df[\"V\"][i] =fill_nan\n",
    "            indx.append(i)\n",
    "            \n",
    "        if np.abs(df['W(3m)'][i])> m_speed:\n",
    "            df.at[i, \"W(3m)\"] = fill_nan\n",
    "            #df['W'][i] = fill_nan\n",
    "            indx.append(i)\n",
    "            \n",
    "        if df['T(3m)'][i] < min_T:\n",
    "            df.at[i, \"T(3m)\"] = fill_nan\n",
    "            #df['T'][i] = fill_nan\n",
    "            indx.append(i)\n",
    "    \n",
    "    if len(indx) ==0:\n",
    "        print(\"Data fits these limits\")\n",
    "    if len(indx) != 0:\n",
    "        print(\"Removed \"+str(len(indx))+\" Values\" )\n",
    "    \n",
    "    df.fillna(value=fill_nan, inplace=True)\n",
    "    df = df.drop(\"DIAG\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There Were 0 Missing Timestamps\n",
      "Default Corrections: -1*U, -1*V, Max Wind Speed=|40| m/s, Min Temperature = -10.0 C  \n",
      "Would you like to change these corrections? (y/n): n\n",
      "Would you like to change the NaN's to a different value? (y/n):y\n",
      "What to replace NaN's with? ex: 9999:NaN\n",
      "Removed 7088 Values\n",
      "Removed 152 Values\n",
      "Removed 128 Values\n",
      "Removed 240 Values\n",
      "Would like the TIMESTAMP column broken up? (y/n):n\n"
     ]
    }
   ],
   "source": [
    "df_list = correction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                     TIMESTAMP U(3m) V(3m) W(3m) T(3m)    P(3m)\n",
       " 0      2019-03-13 12:49:18.000  0.18  0.57  0.08  9.19  1024.65\n",
       " 1      2019-03-13 12:49:18.100  0.22  0.56 -0.02  9.11  1024.61\n",
       " 2      2019-03-13 12:49:18.200  0.15  0.47  0.09  9.16  1024.59\n",
       " 3      2019-03-13 12:49:18.300   0.1  0.56     0  9.11   1024.6\n",
       " 4      2019-03-13 12:49:18.400 -0.02  0.55 -0.07  9.04  1024.62\n",
       " ...                        ...   ...   ...   ...   ...      ...\n",
       " 149523 2019-03-13 16:58:30.300 -0.19  0.73  0.19  8.77  1022.22\n",
       " 149524 2019-03-13 16:58:30.400 -0.19  0.73  0.19  8.77  1022.24\n",
       " 149525 2019-03-13 16:58:30.500 -0.19  0.73  0.19  8.77  1022.28\n",
       " 149526 2019-03-13 16:58:30.600  -0.2  0.74  0.12   8.7  1022.28\n",
       " 149527 2019-03-13 16:58:30.700 -0.22  0.66  0.04  8.75  1022.26\n",
       " \n",
       " [149528 rows x 6 columns],\n",
       "                      TIMESTAMP U(3m) V(3m) W(3m) T(3m)     P(3m)\n",
       " 0      2019-03-13 12:49:18.000  0.63 -0.03 -0.07  8.45  1023.905\n",
       " 1      2019-03-13 12:49:18.100  0.89    -0 -0.04  8.49  1023.921\n",
       " 2      2019-03-13 12:49:18.200  0.96 -0.02  0.03  8.54  1023.914\n",
       " 3      2019-03-13 12:49:18.300  0.78 -0.29  0.01  8.59  1023.914\n",
       " 4      2019-03-13 12:49:18.400  0.48 -0.23  0.02  8.57  1023.851\n",
       " ...                        ...   ...   ...   ...   ...       ...\n",
       " 149523 2019-03-13 16:58:30.300  0.17 -0.27  0.06  8.27  1021.276\n",
       " 149524 2019-03-13 16:58:30.400  0.18 -0.36  0.09  8.29  1021.291\n",
       " 149525 2019-03-13 16:58:30.500  0.29 -0.25  0.12  8.37  1021.299\n",
       " 149526 2019-03-13 16:58:30.600  0.32 -0.08  0.16   8.3  1021.302\n",
       " 149527 2019-03-13 16:58:30.700  0.39 -0.11  0.08   8.3  1021.310\n",
       " \n",
       " [149528 rows x 6 columns],\n",
       "                      TIMESTAMP U(3m) V(3m) W(3m)  T(3m)     P(3m)\n",
       " 0      2019-03-13 12:49:18.000 -0.19  0.79  0.54  11.86  1023.928\n",
       " 1      2019-03-13 12:49:18.100 -0.09  0.87  0.46   11.4  1023.892\n",
       " 2      2019-03-13 12:49:18.200 -0.08  0.87  0.36  10.95  1023.917\n",
       " 3      2019-03-13 12:49:18.300 -0.07  0.85   0.2  10.46  1023.891\n",
       " 4      2019-03-13 12:49:18.400 -0.17  0.91  0.11  10.46  1023.903\n",
       " ...                        ...   ...   ...   ...    ...       ...\n",
       " 149523 2019-03-13 16:58:30.300  -0.4   0.8 -0.22   9.02  1021.230\n",
       " 149524 2019-03-13 16:58:30.400  -0.4  0.74 -0.17   9.02  1021.221\n",
       " 149525 2019-03-13 16:58:30.500 -0.47  0.74 -0.22   9.02  1021.229\n",
       " 149526 2019-03-13 16:58:30.600  -0.4  0.89 -0.26   9.07  1021.222\n",
       " 149527 2019-03-13 16:58:30.700 -0.37  0.81 -0.31   9.07  1021.198\n",
       " \n",
       " [149528 rows x 6 columns],\n",
       "                      TIMESTAMP U(3m) V(3m) W(3m) T(3m)     P(3m)\n",
       " 0      2019-03-13 12:49:18.000 -0.27  0.84  -0.3  8.47  1023.994\n",
       " 1      2019-03-13 12:49:18.100 -0.26  0.83 -0.28  8.49  1023.930\n",
       " 2      2019-03-13 12:49:18.200 -0.24  0.76 -0.42   8.5  1023.950\n",
       " 3      2019-03-13 12:49:18.300 -0.17  0.72 -0.69  8.37  1023.945\n",
       " 4      2019-03-13 12:49:18.400 -0.27  0.82 -0.59   8.3  1023.923\n",
       " ...                        ...   ...   ...   ...   ...       ...\n",
       " 149523 2019-03-13 16:58:30.300 -0.43  0.49 -0.19  8.72  1021.406\n",
       " 149524 2019-03-13 16:58:30.400 -0.46  0.46 -0.18   8.7  1021.380\n",
       " 149525 2019-03-13 16:58:30.500 -0.35  0.39 -0.19  8.69  1021.355\n",
       " 149526 2019-03-13 16:58:30.600  -0.4  0.47 -0.16  8.69  1021.364\n",
       " 149527 2019-03-13 16:58:30.700 -0.48  0.48 -0.08  8.74  1021.349\n",
       " \n",
       " [149528 rows x 6 columns]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
